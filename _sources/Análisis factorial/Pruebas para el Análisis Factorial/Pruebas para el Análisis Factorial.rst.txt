Pruebas para el Análisis Factorial
----------------------------------

.. code:: r

    datos <- read.csv("EAM_2019.csv", sep = ";", dec = ",", header = T)
    print(head(datos))


.. parsed-literal::

      ï..ciiu personal_mujer personal_hombre gasto_personal gasto_financiero
    1    1051             36             140        9352991          3240559
    2    1030             40             176        7334998          1468298
    3    3290             15             172        6668544          1547666
    4    3091             88             373       22088759         35203208
    5    3290             18              53        5219070          2861773
    6    3290             18              53        5219070          2861773
      costos_gastos_produccion gastos_adm_ventas inversion_AF    ventas
    1                  6846304          22920307      4979745 192609248
    2                  5941761          12310286      5615593 115741258
    3                  6996020           2564695       773444  44580029
    4                  4175751         171278876     10501572 162509864
    5                 11037978          13691919      6423171  87324374
    6                 11037978          13691919      6423171  87324374
    

Matriz de correlaciones:
~~~~~~~~~~~~~~~~~~~~~~~~

.. code:: r

    library("corrplot")


.. parsed-literal::

    corrplot 0.92 loaded
    
    

.. code:: r

    corr <- cor(datos[,2:9])

.. code:: r

    corrplot(corr, method = "circle")
    corrplot(corr, method = "number")



.. image:: output_5_0.png
   :width: 420px
   :height: 420px



.. image:: output_5_1.png
   :width: 420px
   :height: 420px


Determinante de la matriz de correlaciones:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Determinante cercano a cerco indica alta multicolinealidad. Esto
significa que algunas variables son linealmente dependientes y una o más
variables podrían ser expresadas como combinación lineal de otras variables
y la técnica del Análisis Factorial es pertinente para analizar las
variables.

.. code:: r

    det(corr)



.. raw:: html

    0.00177061888189585


Test de Bartlett o test de esfericidad:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Se evalúa si la matriz de correlaciones es la identidad :math:`I`.
Significa que las intercorrelaciones entre las variables son cero y el
modelo de Análisis Factorial es inadecuado.

.. math::  H_0: Corr = I 

.. math::  H_0: Corr \neq I 

Se acepta la hipótesis nula si :math:`Valor-p > 0,05`

.. code:: r

    bartlett.test(datos[,2:9])



.. parsed-literal::

    
    	Bartlett test of homogeneity of variances
    
    data:  datos[, 2:9]
    Bartlett's K-squared = 29209, df = 7, p-value < 2.2e-16
    


Se rechaza la hipótesis nula porque :math:`Valor-p = 2,2e-16 < 0,05`, la
matriz de correlaciones no es la Identidad. La aplicación del Análisis
Factorial es adecuada. Esta afirmación también está soportada por el
Determinante cercano a cero.

Kaiser-Meyer-Olkin - KMO:
-------------------------

Con esta prueba se busca si entre las variables hay factores comunes. Si
las variables comparten factores comunes, el coeficiente de correlación
parcial entre pares de variables es cercano a cero. Con los coeficientes
de correlación parcial se mide el grado de relación lineal entre dos
variables sin el efecto de las demás. Si se tienen coeficientes de
correlación parcial altos, la aplicación del Análisis Factorial no es el
adecuado.

Para comprobar lo anterior se calcula una Medida de Adecuación de la
Muestra de KMO, :math:`0<=KMO<=1`.

.. math::  KMO <0,6 --> Inaceptable 

.. math::  KMO >=0,6 --> Aceptable 

.. math::  KMO >=0,7 --> Bien 

Con KMO cercano a cero indica que las correlaciones entre pares de
variables no pueden ser explicadas por otras variables.

.. math::  KMO = \frac{\sum_{j\neq i}\sum_{i\neq j}r^2_{ij}}{\sum_{j\neq i}\sum_{i\neq j}r^2_{ij}+\sum_{j\neq i}\sum_{i\neq j}r^2_{ij(p)}}  

Donde,

:math:`r^2_{ij(p)}`: coeficiente de correlación parcial entre
:math:`(X_i, X_i)`.

Para esta prueba instalar el paquete: ``install.packages("psych")``

.. code:: r

    library(psych)

.. code:: r

    KMO(datos[,2:9])



.. parsed-literal::

    Kaiser-Meyer-Olkin factor adequacy
    Call: KMO(r = datos[, 2:9])
    Overall MSA =  0.67
    MSA for each item = 
              personal_mujer          personal_hombre           gasto_personal 
                        0.63                     0.63                     0.67 
            gasto_financiero costos_gastos_produccion        gastos_adm_ventas 
                        0.47                     0.85                     0.64 
                inversion_AF                   ventas 
                        0.84                     0.63 


Como :math:`KMO = 0,67` es aceptable aplicar el Análisis Factorial
porque sí hay presencia de factores comunes.
